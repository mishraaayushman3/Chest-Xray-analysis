# -*- coding: utf-8 -*-
"""Draft AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ozp7kmqQcIsQCrl-2gGNop8BHbgJEh0D

## Import the libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import os
# %matplotlib inline
import matplotlib.pyplot as plt
from os import listdir
from os.path import isfile, join
from keras.applications.mobilenet import MobileNet
from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten
from keras.models import Sequential
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator

"""## Read the Data"""

#Read the sample_labels.csv into a pandas dataframe
xray_df = pd.read_csv('drive/My Drive/Chest_data/sample/sample_labels.csv')
image_paths = {os.path.basename(f): f  for f in listdir("drive/My Drive/Chest_data/sample/images")   }             
print('Images found:', len(image_paths), ', Total Headers', xray_df.shape[0])
xray_df['path'] = xray_df['Image Index'].map(image_paths.get)
xray_df['Patient Age'] = xray_df['Patient Age'].map(lambda x: int(x[:-1]))
xray_df.sample(3)

# Since the image may contain multiple disease labels
# Create a list of all disesases and append a new column named output to the x_ray dataframe
xray_df['output']=xray_df['Finding Labels'].apply(lambda x: x.split('|'))
xray_df['Finding Labels'] = xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))

# check if the new column has been created correctly
xray_df.head()

diseases=['Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','Nodule','Pneumonia','Pneumothorax','Consolidation','Edema','Emphysema','Fibrosis','Pleural Thickening','Hernia']

# since the dataset is very unbiased, we can resample it to be a more reasonable collection
# weight is 0.1 + number of findings
sample_weights = xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2
sample_weights /= sample_weights.sum()
xray_df = xray_df.sample(5606, weights=sample_weights)

label_counts = xray_df['Finding Labels'].value_counts()[:15]
fig, ax1 = plt.subplots(1,1,figsize = (12, 8))
ax1.bar(np.arange(len(label_counts))+0.5, label_counts)
ax1.set_xticks(np.arange(len(label_counts))+0.5)
_ = ax1.set_xticklabels(label_counts.index, rotation = 90)

"""## Split the data into training and test set"""

# 20% of the data will be used for testing of model performance
# random state is set so as to get the same split everytime
# stratify is used to have equal proportion of output label in training and validation set
train_df, valid_df = train_test_split(xray_df, 
                                   test_size = 0.20, 
                                   random_state = 2018,
                                   stratify = xray_df['Finding Labels'].map(lambda x: x[:4]))
print('train', train_df.shape[0], 'validation', valid_df.shape[0])

IMG_SIZE = (128, 128)
#creating an Image Data generator
core_idg = ImageDataGenerator(samplewise_center=True, 
                              samplewise_std_normalization=True, 
                              horizontal_flip = True, 
                              vertical_flip = False, 
                              height_shift_range= 0.05, 
                              width_shift_range=0.1, 
                              rotation_range=5, 
                              shear_range = 0.1,
                              fill_mode = 'reflect',
                              zoom_range=0.15,
                              validation_split = 0.1)

train_df.head()

# obtaing the training images using the above generator
train_gen = core_idg.flow_from_dataframe(
        dataframe=train_df,
        directory='drive/My Drive/Chest_data/sample/images',
        x_col='path',
        y_col='output',
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical',subset='training')

# obtaing the validation images using the above generator
valid_gen = core_idg.flow_from_dataframe(
        dataframe=train_df,
        directory='drive/My Drive/Chest_data/sample/images',
        x_col='path',
        y_col='output',
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical',subset='validation')

# print the output classes in ImageDataGenerator train_gen
train_gen.class_indices.keys()

#select a batch of images used for prediction on trained model
test_X, test_Y = next(core_idg.flow_from_dataframe(
        dataframe=valid_df,
        directory='drive/My Drive/Chest_data/sample/images',
        x_col='path',
        y_col='output',
        target_size=(128, 128),
        batch_size=1024,
        class_mode='categorical')) # one big batch

"""## Model"""

# create a function to return a mobileNetModel with the output layer having 15 output units
def mobilenet_model():
  base_mobilenet_model = MobileNet(input_shape =  (128, 128, 3), include_top = False, weights = None)
  model = Sequential()
  model.add(base_mobilenet_model)
  model.add(GlobalAveragePooling2D())
  model.add(Dropout(0.5))
  model.add(Dense(512,activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(15, activation = 'sigmoid'))
  return model

# choose an appropriate model and compile
model=mobilenet_model()
model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['binary_accuracy', 'mae'])
# print the model details
model.summary()

# creating a callback to store the best model
weight_path="{}_weights.best.hdf5".format('xray_class')
checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, 
                             save_best_only=True, mode='min', save_weights_only = True)
early = EarlyStopping(monitor="val_loss", 
                      mode="min", 
                      patience=3)
callbacks_list = [checkpoint, early]

# start training the model
model.fit_generator(train_gen, 
                    steps_per_epoch=100,
                    validation_data=valid_gen,
                    epochs = 5, 
                    callbacks = callbacks_list)

# load the best weights
model.load_weights(weight_path)
# predict on the test_X batch of the validation set
res = model.evaluate(test_X,test_Y batch_size = 32, verbose = True)

print('loss = ',res[0])
print('Binary accuracy = ',res[1])
print('Mean absolute error',res[2])

# visualising model performance
sickest_idx = np.argsort(np.sum(test_Y, 1)<1)
fig, m_axs = plt.subplots(4, 2, figsize = (16, 32))
for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):
    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')
    stat_str = [n_class[:6] for n_class, n_score in zip(diseases, 
                                                                  test_Y[idx]) 
                             if n_score>0.5]
    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(diseases, 
                                                                  test_Y[idx], pred_Y[idx]) 
                             if (n_score>0.5) or (p_score>0.5)]
    c_ax.set_title('Dx: '+', '.join(stat_str)+'\nPDx: '+', '.join(pred_str))
    c_ax.axis('off')
fig.savefig('trained_img_predictions.png')

